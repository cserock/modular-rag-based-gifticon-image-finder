{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG : Coupon Image Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# project 명\n",
    "PROJECT = 'arpo-eval'\n",
    "\n",
    "# project root 경로\n",
    "PROJECT_ROOT_PATH = '.'\n",
    "\n",
    "# default LLM 설정\n",
    "DEFAULT_LLM = 'OPENAI' # 'UPSTAGE', 'OLLAMA'\n",
    "\n",
    "# default embedding model 설정\n",
    "DEFAULT_EMBEDDING_MODEL = 'OPENAI' # 'UPSTAGE', 'OLLAMA'\n",
    "\n",
    "# coupon image 파일 경로\n",
    "IMAGE_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_image_files'\n",
    "\n",
    "# OCR 모델에서 추출한 coupon 정보의 Ground Truth 정보가 저장된 파일 경로\n",
    "COUPON_INFO_GT_JSON_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_info_gt.json'\n",
    "\n",
    "# Pororo OCR 모델에서 추출한 coupon 정보가 저장된 coupon_infos.json 파일 경로\n",
    "COUPON_INFO_JSON_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_info.json'\n",
    "\n",
    "# Upstage OCR 모델에서 추출한 coupon 정보가 저장된 coupon_infos_upstage.json 파일 경로\n",
    "COUPON_INFO_UPSTAGE_JSON_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_info_upstage.json'\n",
    "\n",
    "# EasyOCR 모델에서 추출한 coupon 정보가 저장된 coupon_infos_easy.json 파일 경로\n",
    "COUPON_INFO_EASY_JSON_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_infos_easy.json'\n",
    "\n",
    "# gpt-4o 모델에서 추출한 coupon 정보가 저장된 coupon_infos_gpt_4o.json 파일 경로\n",
    "COUPON_INFO_GPT_4O_JSON_PATH = f'{PROJECT_ROOT_PATH}/data/coupon_infos_gpt_4o.json'\n",
    "\n",
    "# VectorDB 저장 경로\n",
    "VECTOR_DB_ROOT_PATH = f'{PROJECT_ROOT_PATH}/.vector_db'\n",
    "\n",
    "# FAISS 저장 경로\n",
    "FAISS_DB_PATH = f'{VECTOR_DB_ROOT_PATH}/faiss'\n",
    "\n",
    "# FAISS index 이름\n",
    "FAISS_INDEX_NAME = 'coupon'\n",
    "\n",
    "# Chroma 저장 경로\n",
    "CHROMA_DB_PATH = f'{VECTOR_DB_ROOT_PATH}/chroma'\n",
    "\n",
    "# Chroma collection 이름\n",
    "CHROMA_COLLECTION_NAME = \"coupon\"\n",
    "\n",
    "# PINECONE 저장 경로\n",
    "PINECONE_DB_PATH = f'{VECTOR_DB_ROOT_PATH}/pinecone'\n",
    "\n",
    "# PINECONE index 이름\n",
    "PINECONE_INDEX_NAME = 'coupon'\n",
    "\n",
    "# cache 경로 설정\n",
    "CACHE_PATH = f'{PROJECT_ROOT_PATH}/.cache'\n",
    "\n",
    "# LLM CACHE 경로 설정\n",
    "LLM_CACHE_PATH = f'{CACHE_PATH}/multimodal-rag_cache.db'\n",
    "\n",
    "# env 설정 로딩\n",
    "load_dotenv(verbose=True, override=True)\n",
    "\n",
    "# 캐시 디렉토리를 생성합니다.\n",
    "if not os.path.exists(CACHE_PATH):\n",
    "    os.makedirs(CACHE_PATH)\n",
    "\n",
    "# SQLiteCache를 사용합니다.\n",
    "set_llm_cache(SQLiteCache(database_path=LLM_CACHE_PATH))\n",
    "\n",
    "# langsmith 추적 시작\n",
    "logging.langsmith(PROJECT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_llm() : default LLM을 초기화하여 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "def get_llm(model=DEFAULT_LLM):\n",
    "    if model == 'OPENAI':\n",
    "        # model : gpt-4o-mini\n",
    "        llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.0,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "    elif model == 'UPSTAGE':\n",
    "        # model : Upstage solar-pro\n",
    "        llm = ChatUpstage(\n",
    "            model=\"solar-pro\",\n",
    "            temperature=0.0,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "    elif model == 'OLLAMA':\n",
    "        # model : EEVE-Korean-Instruct-10.8B:latest\n",
    "        llm = ChatOllama(\n",
    "            model=\"EEVE-Korean-Instruct-10.8B:latest\",  \n",
    "            temperature=0.0,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "    return llm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "llm = get_llm()\n",
    "print(llm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_embedding() : 설정한 default Embedding model을 초기화하여 리턴합니다.\n",
    "\n",
    "- OpenAI\n",
    "  - text-embedding-3-small : $0.02 / 1M tokens\n",
    "  - text-embedding-3-large : $0.13 / 1M tokens\n",
    "  - text-embedding-ada-002 : $0.1 / 1M tokens\n",
    "  - dimension : 1536\n",
    "- Upstage\n",
    "  - Embeddings : $0.1 / 1M tokens\n",
    "  - dimension : 4096\n",
    "- Ollama\n",
    "  - nomic-embed-text : open source"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "def get_embedding(embedding_model=DEFAULT_EMBEDDING_MODEL):\n",
    "    if embedding_model == 'OPENAI':\n",
    "        # OpenAIEmbeddings\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    elif embedding_model == 'UPSTAGE':\n",
    "        # UpstageEmbeddings\n",
    "        embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "    elif embedding_model == 'OLLAMA':\n",
    "        # ollama pull nomic-embed-text 실행 필요\n",
    "        embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    return embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "embedding = get_embedding()\n",
    "print(embedding)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. OCR 모델을 통한 이미지 정보 분석\n",
    "- Pororo : https://kakaobrain.github.io/pororo/miscs/ocr.html\n",
    "- Upstage OCR : https://developers.upstage.ai/docs/apis/document-ocr\n",
    "- EasyOCR : https://github.com/JaidedAI/EasyOCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from pprint import pprint\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    max_tokens=2048,\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# OCR 모델 평가용 prompt\n",
    "system_prompt = \"\"\"You are an Optical Character Recognition machine.\"\"\"\n",
    "user_prompt = \"\"\"You will extract all the characters from the image provided by the user, and you will only privide the extracted text in your response.\n",
    "As an OCR machine, You can only respond with the extracted text according to the following intruction.\n",
    "* Even if there are line breaks, if it is inferred that it is a product name, please represent it as a passage.\n",
    "* Answer in the form of a python list that looks like the example below.\n",
    "example : ['element_1','element_2',...,'elemnet_N']\n",
    "\"\"\"\n",
    "\n",
    "# 멀티모달 객체 생성\n",
    "multimodal_llm = MultiModal(\n",
    "    llm, system_prompt=system_prompt, user_prompt=user_prompt\n",
    ")\n",
    "\n",
    "img_path = f'{IMAGE_PATH}/coupon_rock_12.jpeg'\n",
    "result = multimodal_llm.invoke(img_path, display_image=False)\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Pororo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pororo_ocr import PororoOcr\n",
    "\n",
    "ocr = PororoOcr()\n",
    "ocr.get_available_langs()\n",
    "ocr.get_available_models()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "img_path = f'{IMAGE_PATH}/coupon_rock_12.jpeg'\n",
    "result = ocr.run_ocr(img_path, debug=True)\n",
    "# ocr.get_ocr_result()\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Upstage\n",
    "- Document OCR : $0.0015 / page"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "# api_key = 'up_n5wUAJPBxfmHMaCbrfaevBkSfFXOG'\n",
    "img_path = f'{IMAGE_PATH}/coupon_rock_12.jpeg'\n",
    "\n",
    "url = \"https://api.upstage.ai/v1/document-ai/ocr\"\n",
    "headers = {\"Authorization\": f\"Bearer {os.getenv('UPSTAGE_API_KEY')}\"}\n",
    "files = {\"document\": open(img_path, \"rb\")}\n",
    "response = requests.post(url, headers=headers, files=files)\n",
    "result = response.json()\n",
    "# print(result[\"pages\"][0]['text'])\n",
    "\n",
    "result_text = result[\"pages\"][0]['text']\n",
    "result_list = result_text.split(' \\n')\n",
    "print(result_list)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) EasyOCR\n",
    "- open source"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import easyocr\n",
    "\n",
    "img_path = f'{IMAGE_PATH}/coupon_rock_12.jpeg'\n",
    "\n",
    "reader = easyocr.Reader(['ko','en']) # this needs to run only once to load the model into memory\n",
    "result = reader.readtext(img_path, detail = 0, paragraph=True)\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mulltimodal Model을 사용하여 coupon 이미지 분류\n",
    "- 로컬에 설치된 llava:13b를 사용 : https://ollama.com/library/llava:13b\n",
    "- prompt를 통해 해당 이미지가 coupon 이미지인지를 검사하고 결과를 TRUE, FALSE로 답변함"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "def convert_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    PIL 이미지를 Base64로 인코딩된 문자열로 변환합니다.\n",
    "\n",
    "    :param pil_image: PIL 이미지\n",
    "    :return: 크기 조정된 Base64 문자열\n",
    "    \"\"\"\n",
    "    file_ext = os.path.splitext(image_path)[1].lower()\n",
    "    if file_ext in [\".jpg\", \".jpeg\"]:\n",
    "        format = \"JPEG\"\n",
    "    elif file_ext == \".png\":\n",
    "        format = \"PNG\"\n",
    "    else:\n",
    "        format = \"JPEG\"\n",
    "    \n",
    "    pil_image = Image.open(image_path)\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=format)\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "def prompt_func(data):  # 프롬프트 함수를 정의합니다.\n",
    "    text = data[\"text\"]  # 데이터에서 텍스트를 가져옵니다.\n",
    "    image = data[\"image\"]  # 데이터에서 이미지를 가져옵니다.\n",
    "\n",
    "    image_part = {  # 이미지 부분을 정의합니다.\n",
    "        \"type\": \"image_url\",  # 이미지 URL 타입을 지정합니다.\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image}\",  # 이미지 URL을 생성합니다.\n",
    "    }\n",
    "\n",
    "    content_parts = []  # 콘텐츠 부분을 저장할 리스트를 초기화합니다.\n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text}  # 텍스트 부분을 정의합니다.\n",
    "\n",
    "    content_parts.append(image_part)  # 이미지 부분을 콘텐츠 부분에 추가합니다.\n",
    "    content_parts.append(text_part)  # 텍스트 부분을 콘텐츠 부분에 추가합니다.\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]  # HumanMessage 객체를 반환합니다.\n",
    "\n",
    "def infer_coupon_image(image_path):\n",
    "    image_b64 = convert_to_base64(image_path)\n",
    "\n",
    "    mmlm = ChatOllama(model=\"llava:13b\", temperature=0)\n",
    "\n",
    "    # 프롬프트 함수, 언어 모델, 출력 파서를 연결하여 체인을 생성합니다.\n",
    "    chain = prompt_func | mmlm | StrOutputParser()\n",
    "\n",
    "    output = chain.invoke(  # 체인을 호출하여 쿼리를 실행합니다.\n",
    "        # 텍스트와 이미지를 전달합니다.\n",
    "        {\"text\": \"Is the image a coupon containing a barcode for ordering something? Please answer TRUE or FALSE.\", \"image\": image_b64}\n",
    "    )\n",
    "    return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타킷 폴더(IMAGE_PATH) 하위의 이미지 파일들에 대해 coupon 이미지 분류작업 실행"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "target_file_names = os.listdir(IMAGE_PATH)\n",
    "target_file_names = [target_file_name for target_file_name in target_file_names if not target_file_name.startswith ('.')] #.DS_Store 제외\n",
    "# print(target_file_names)\n",
    "coupon_file_names = []\n",
    "for target_file_name in target_file_names:\n",
    "    image_path = f'{IMAGE_PATH}/{target_file_name}'\n",
    "    result = infer_coupon_image(image_path)\n",
    "    \n",
    "    if 'TRUE' in result:\n",
    "        coupon_file_names.append(image_path)\n",
    "\n",
    "print(coupon_file_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coupon_file_names은 OCR 모델을 통해 쿠폰이미지에서 추출한 text와 이미지 경로입니다.  \n",
    "이를 통해 LLM을 통해 쿠폰 정보를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pororo_ocr import PororoOcr\n",
    "import json\n",
    "\n",
    "ocr = PororoOcr()\n",
    "\n",
    "# 결과\n",
    "# sources = [\n",
    "#     {\n",
    "#         \"coupon_info\": \"['푸라닭 씬 후라이드+블랙치즈볼(5구)+ 콜라 1.25L','푸라닭 치킨','7250 4472 7165','교환처','푸라닭','유효기간','2025년 03월 22일','주문번호','2438016287','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_01.jpeg\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"coupon_info\": \"['스타벅스 아이스 카페 아메리카노 T','7508 4738 7755 0468','교환처','스타벅스','유효기간','2025년 08월 06일','주문번호','2574597164','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_02.jpeg\"\n",
    "#     },\n",
    "#      ...\n",
    "# ]\n",
    "sources = []\n",
    "\n",
    "for coupon_file_name in coupon_file_names:\n",
    "    coupon_info = ocr.run_ocr(coupon_file_name)\n",
    "    coupon_info_text = \"','\".join(coupon_info)\n",
    "    result = {\n",
    "        \"coupon_info\": f\"['{coupon_info_text}']\",\n",
    "        \"image_path\": coupon_file_name\n",
    "    }\n",
    "    sources.append(result)\n",
    "\n",
    "print(sources)\n",
    "\n",
    "# COUPON_INFO_JSON_PATH에 sources 리스트를 json 타입으로 저장\n",
    "with open(COUPON_INFO_JSON_PATH, 'w', encoding=\"UTF-8\") as f :\n",
    "    json.dump(sources, f, indent=4, ensure_ascii=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "def run_upstage_ocr(img_path):\n",
    "    api_endpoint = \"https://api.upstage.ai/v1/document-ai/ocr\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('UPSTAGE_API_KEY')}\"}\n",
    "    files = {\"document\": open(img_path, \"rb\")}\n",
    "    response = requests.post(api_endpoint, headers=headers, files=files)\n",
    "    result = response.json()\n",
    "\n",
    "    print(result)\n",
    "    # print(result[\"pages\"][0]['text'])\n",
    "\n",
    "    result_text = result[\"pages\"][0]['text']\n",
    "    result_list = result_text.split(' \\n')\n",
    "    print(result_list)\n",
    "    return result_list\n",
    "\n",
    "# 결과\n",
    "# sources = [\n",
    "#     {\n",
    "#         \"coupon_info\": \"['푸라닭 씬 후라이드+블랙치즈볼(5구)+ 콜라 1.25L','푸라닭 치킨','7250 4472 7165','교환처','푸라닭','유효기간','2025년 03월 22일','주문번호','2438016287','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_01.jpeg\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"coupon_info\": \"['스타벅스 아이스 카페 아메리카노 T','7508 4738 7755 0468','교환처','스타벅스','유효기간','2025년 08월 06일','주문번호','2574597164','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_02.jpeg\"\n",
    "#     },\n",
    "#      ...\n",
    "# ]\n",
    "sources_upstage = []\n",
    "\n",
    "for coupon_file_name in coupon_file_names:\n",
    "    coupon_info = run_upstage_ocr(coupon_file_name)\n",
    "    coupon_info_text = \"','\".join(coupon_info)\n",
    "    result = {\n",
    "        \"coupon_info\": f\"['{coupon_info_text}']\",\n",
    "        \"image_path\": coupon_file_name\n",
    "    }\n",
    "    sources_upstage.append(result)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(sources_upstage)\n",
    "\n",
    "# COUPON_INFO_JSON_PATH에 sources 리스트를 json 타입으로 저장\n",
    "with open(COUPON_INFO_UPSTAGE_JSON_PATH, 'w', encoding=\"UTF-8\") as f :\n",
    "    json.dump(sources_upstage, f, indent=4, ensure_ascii=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import easyocr\n",
    "import json\n",
    "\n",
    "reader = easyocr.Reader(['ko','en']) # this needs to run only once to load the model into memory\n",
    "\n",
    "# 결과\n",
    "# sources = [\n",
    "#     {\n",
    "#         \"coupon_info\": \"['푸라닭 씬 후라이드+블랙치즈볼(5구)+ 콜라 1.25L','푸라닭 치킨','7250 4472 7165','교환처','푸라닭','유효기간','2025년 03월 22일','주문번호','2438016287','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_01.jpeg\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"coupon_info\": \"['스타벅스 아이스 카페 아메리카노 T','7508 4738 7755 0468','교환처','스타벅스','유효기간','2025년 08월 06일','주문번호','2574597164','kakaotalk 선물하기']\",\n",
    "#         \"image_path\": \"./data/coupon_image_files/coupon_A_02.jpeg\"\n",
    "#     },\n",
    "#      ...\n",
    "# ]\n",
    "sources = []\n",
    "\n",
    "for coupon_file_name in coupon_file_names:\n",
    "    coupon_info = reader.readtext(coupon_file_name, detail = 0, paragraph=True)\n",
    "    coupon_info_text = \"','\".join(coupon_info)\n",
    "    result = {\n",
    "        \"coupon_info\": f\"['{coupon_info_text}']\",\n",
    "        \"image_path\": coupon_file_name\n",
    "    }\n",
    "    sources.append(result)\n",
    "\n",
    "print(sources)\n",
    "\n",
    "# COUPON_INFO_JSON_PATH에 sources 리스트를 json 타입으로 저장\n",
    "with open(COUPON_INFO_EASY_JSON_PATH, 'w', encoding=\"UTF-8\") as f :\n",
    "    json.dump(sources, f, indent=4, ensure_ascii=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4o를 사용한 쿠폰 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import MultiModal\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    max_tokens=2048,\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# system_prompt = \"\"\"당신은 쿠폰 이미지에서 쿠폰 정보를 키워드로 추출하는 이미지 분석 AI 어시스턴트 입니다. \n",
    "# 당신의 임무는 주어진 쿠폰 이미지에서 쿠폰 정보를 키워드로 추출하는 것입니다.\"\"\"\n",
    "\n",
    "# user_prompt = \"\"\"당신에게 주어진 이미지는 상품과 교환이 가능한 쿠폰 이미지입니다. \n",
    "# 이미지로부터 반드시 <상품명>, <쿠폰번호>, <유효기간>, <구매처> 또는 <교환처>, <주문번호>에 해당하는 쿠폰정보를 키워드로 추촐해서 ,(comma)로 구분된 리스트 형태의 문자열로 답변해 주세요.\n",
    "# 예) 'key_1:value_1', 'key_2:value_2', ..., 'key_n:value_n'\n",
    "# \"\"\"\n",
    "\n",
    "# OCR 모델 평가용 prompt\n",
    "system_prompt = \"\"\"You are an Optical Character Recognition machine.\"\"\"\n",
    "user_prompt = \"\"\"You will extract all the characters from the image provided by the user, and you will only privide the extracted text in your response.\n",
    "As an OCR machine, You can only respond with the extracted text according to the following intruction.\n",
    "* Even if there are line breaks, if it is inferred that it is a product name, please represent it as a passage.\n",
    "* Answer with a string in the format of the example below.\n",
    "example : ['element_1','element_2',...,'elemnet_N']\n",
    "\"\"\"\n",
    "\n",
    "# 멀티모달 객체 생성\n",
    "multimodal_llm = MultiModal(\n",
    "    llm, system_prompt=system_prompt, user_prompt=user_prompt\n",
    ")\n",
    "\n",
    "sources_gpt_4o = []\n",
    "for coupon_file_name in coupon_file_names:\n",
    "    coupon_info_text = multimodal_llm.invoke(coupon_file_name, display_image=False)\n",
    "    print(coupon_info_text)\n",
    "    \n",
    "    result = {\n",
    "        # poporo \n",
    "        # \"coupon_info\": f\"['{coupon_info_text}']\",\n",
    "        \n",
    "        # gpt-4o\n",
    "        \"coupon_info\": coupon_info_text,\n",
    "        \"image_path\": coupon_file_name\n",
    "    }\n",
    "    sources_gpt_4o.append(result)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(sources_gpt_4o)\n",
    "\n",
    "# COUPON_INFO_JSON_PATH에 sources 리스트를 json 타입으로 저장\n",
    "with open(COUPON_INFO_JSON_PATH, 'w', encoding=\"UTF-8\") as f :\n",
    "    json.dump(sources_gpt_4o, f, indent=4, ensure_ascii=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리 & 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쿠폰 정보를 임베딩하기 위해 OCR을 통해 얻은 쿠폰 이미지 데이터를 LLM을 통해 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# \n",
    "preprocess_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"<WANT_TO_CACHE_HERE>\n",
    "        당신은 쿠폰 이미지를 OCR 모델을 통해 추출한 키워드로 쿠폰 정보를 추론하는 agent입니다. 추론시 다음의 규칙을 지켜주세요.\n",
    "        - 정보는 주어진 키워드에서만 사용하세요.\n",
    "        - 쿠폰코드는 공백(space) 또는 대시(-)를 포함할 수 있으며 숫자로 구성되어 있습니다.\n",
    "        - 유효기간은 종료일 기준으로 'YYYY년 mm월 dd일'의 형태로 작성해 주세요.\n",
    "        - 유효기간의 연도는 종료일 기준으로 'YYYY'의 형태로 integer 타입으로 작성해 주세요.\n",
    "        - 유효기간의 월은 종료일 기준으로 'm'의 형태로 integer 타입으로 작성해 주세요.\n",
    "        - 유효기간의 일은 종료일 기준으로 'd'의 형태로 integer 타입으로 작성해 주세요.\n",
    "        - 오타가 있을 수 있으니 맞춤법에 맞게 수정해 주세요.\n",
    "\n",
    "        다음은 OCR 모델을 통해 추출한 쿠폰 키워드입니다. 이 정보를 바탕으로 쿠폰정보를 추론해 주세요.\n",
    "        답변 출력시 추론에 대한 설명은 제외하고 아래 FORMAT을 참고해서 json형태로만 출력해 주세요.\n",
    "        </WANT_TO_CACHE_HERE>\n",
    "        \n",
    "        KEYWORD:\n",
    "        {coupon_info}\n",
    "\n",
    "        FORMAT:\n",
    "        {format}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "class CouponSummary(BaseModel):\n",
    "    title: str = Field(description=\"쿠폰이름\")\n",
    "    coupon_code: str = Field(description=\"쿠폰코드\")\n",
    "    publisher: str = Field(description=\"교환처\")\n",
    "    valid_date: str = Field(description=\"유효기간\")\n",
    "    order_number: str = Field(description=\"주문번호\")\n",
    "    summary: str = Field(description=\"쿠폰 정보 요약\")\n",
    "    valid_year: int = Field(description=\"유효기간의 연도\")\n",
    "    valid_month: int = Field(description=\"유효기간의 월\")\n",
    "    valid_day: int = Field(description=\"유효기간의 일\")\n",
    "    image_path: Optional[str] = None\n",
    "\n",
    "# PydanticOutputParser 생성\n",
    "preprocess_parser = PydanticOutputParser(pydantic_object=CouponSummary)\n",
    "\n",
    "# instruction 을 출력합니다.\n",
    "print(preprocess_parser.get_format_instructions())\n",
    "preprocess_prompt = preprocess_prompt.partial(format=preprocess_parser.get_format_instructions())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate_coupon_summary()는 쿠폰 정보를 바탕으로 쿠폰 요약(summary)을 생성하기 위한 함수입니다.\n",
    "쿠폰 요약(summary)은 embedding 대상이 되며 RAG에서 retrieval시에 추출되는 context 입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def generate_coupon_summary(coupon_summary: CouponSummary):\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "            당신은 주어진 쿠폰 정보를 자연스러운 한국어 문장으로 설명하는 agent입니다.\n",
    "            아래의 주어진 정보 이외에는 절대 사용하면 안됩니다. 쿠폰코드는 필수로 포함되어야 하며 쿠폰에 대해 자연스러운 한국어 문장으로 설명해 주세요.\n",
    "            - 쿠폰이름 : {title}\n",
    "            - 쿠폰코드 : {coupon_code}\n",
    "            - 발행처 : {publisher}\n",
    "            - 유효기간 : {valid_date}\n",
    "            - 주문번호 : {order_number}\n",
    "            - 쿠폰요약 : {summary}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    input = {\n",
    "        \"title\": coupon_summary.title, \n",
    "        \"coupon_code\": coupon_summary.coupon_code,\n",
    "        \"publisher\": coupon_summary.publisher,\n",
    "        \"valid_date\": coupon_summary.valid_date,\n",
    "        \"order_number\": coupon_summary.order_number, \n",
    "        \"summary\": coupon_summary.summary\n",
    "    }\n",
    "\n",
    "    # llm 로딩\n",
    "    llm = get_llm()\n",
    "    \n",
    "    # 체인 생성\n",
    "    chain = prompt | llm\n",
    "\n",
    "    output = chain.invoke(input)\n",
    "    # print(output.content)\n",
    "    return output.content"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coupon_info.json 파일로부터 sources 변수를 초기화 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json \n",
    "\n",
    "# coupon_info.json 로딩\n",
    "with open(COUPON_INFO_JSON_PATH, \"r\") as f:\n",
    "\tsources = json.load(f)\n",
    "print(sources)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM을 사용하여 OCR에서 추출한 coupon_info로부터 CouponSummary 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# llm 로딩\n",
    "preprocess_llm = get_llm()\n",
    "\n",
    "# 체인 생성\n",
    "preprocess_chain = preprocess_prompt | preprocess_llm\n",
    "\n",
    "result_summary_text = []\n",
    "result_metadata = []\n",
    "result_ids = []\n",
    "\n",
    "# sources에는 coupon_info.json 로부터 로딩한 coupon 정보가 들어있음\n",
    "for source in sources:\n",
    "    input = {\n",
    "        \"coupon_info\": source['coupon_info']\n",
    "    }\n",
    "    \n",
    "    output = preprocess_chain.invoke(input)\n",
    "    structured_output = preprocess_parser.parse(output.content)\n",
    "\n",
    "    # 생성된 쿠폰 요약 추가\n",
    "    structured_output.summary = generate_coupon_summary(structured_output)\n",
    "\n",
    "    # 이미지 path 추가\n",
    "    structured_output.image_path = source['image_path']\n",
    "    \n",
    "    result_ids.append(source['image_path'])\n",
    "    result_summary_text.append(structured_output.summary)\n",
    "    result_metadata.append(structured_output.__dict__)\n",
    "\n",
    "# print(result_ids)\n",
    "print(result_summary_text)\n",
    "print(result_metadata)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorDB 설정 : Chroma\n",
    "Vector DB로 Chroma를 사용하는 경우 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Chroma 생성\n",
    "chroma_coupon_db = Chroma.from_texts(\n",
    "    ids=result_ids, texts=result_summary_text, metadatas=result_metadata, embedding=get_embedding(), persist_directory=CHROMA_DB_PATH, collection_name=CHROMA_COLLECTION_NAME\n",
    ")\n",
    "\n",
    "# Chroma 로딩\n",
    "chroma_coupon_db = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=get_embedding(), collection_name=CHROMA_COLLECTION_NAME)\n",
    "chroma_coupon_db.get()\n",
    "\n",
    "# Chroma 삭제\n",
    "# chroma_coupon_db.reset_collection()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity_search_with_relevance_scores()를 사용하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "chroma_coupon_db.similarity_search_with_relevance_scores(\"GS에서 사용할 수 있는 쿠폰을 알려주세요.\", k=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retriever를 설정하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "chroma_retriever = chroma_coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10})\n",
    "# retriever = coupon_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "# retriever = coupon_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "chroma_retriever.invoke(\"베이글을 주문할 수 있는 쿠폰\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "\n",
    "# 메타데이터 필드 정보 생성\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"coupon_code\",\n",
    "        description=\"The code of <기프티콘> or <쿠폰>\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"order_number\",\n",
    "        description=\"The number the order\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"publisher\",\n",
    "        description=\"The publisher that <기프티콘> or <쿠폰> was published\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"valid_year\",\n",
    "        description=\"Modified year of the valid date of <기프티콘> or <쿠폰>\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"valid_month\",\n",
    "        description=\"Modified month of the valid date of <기프티콘> or <쿠폰>\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"valid_day\",\n",
    "        description=\"Modified day of the valid date of <기프티콘> or <쿠폰>\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# SelfQueryRetriever 생성\n",
    "chroma_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=get_llm(),\n",
    "    search_type='mmr',\n",
    "    vectorstore=chroma_coupon_db,\n",
    "    document_contents=\"Summary of <기프티콘> or <쿠폰>\",\n",
    "    metadata_field_info=metadata_field_info\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Self-query 검색\n",
    "# chroma_retriever.invoke(\"오늘은 2024년 12월 9일입니다. 오늘을 기준으로 유효기간이 한달 이내인 쿠폰을 찾아줘\")\n",
    "# chroma_retriever.invoke(\"기프티콘 유효기간이 2022년 4월 28일인 쿠폰을 찾아줘\")\n",
    "# chroma_retriever.invoke(\"발행처가 스타벅스인 쿠폰을 찾아줘\")\n",
    "# retriever.invoke(\"2024년 12월에 사용해야하는 쿠폰을 찾아줘\")\n",
    "chroma_retriever.invoke(\"2024년내로 사용해야하는 스타벅스 쿠폰을 찾아줘\")\n",
    "# retriever.invoke(\"스타벅스 쿠폰을 찾아줘\")\n",
    "# chroma_retriever.invoke(\"2024년 12월에 사용해야하는 스타벅스 쿠폰을 찾아줘\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorDB 설정 : FAISS\n",
    "Vector DB로 FAISS를 사용하는 경우 초기화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "coupon_db = FAISS.from_texts(\n",
    "    result_summary_text,\n",
    "    embedding=get_embedding(),\n",
    "    metadatas=result_metadata,\n",
    "    ids=result_ids,\n",
    ")\n",
    "\n",
    "# 로컬 Disk 에 저장\n",
    "coupon_db.save_local(folder_path=FAISS_DB_PATH, index_name=FAISS_INDEX_NAME)\n",
    "\n",
    "# 저장된 내용 확인\n",
    "coupon_db.docstore._dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 저장된 데이터를 로드\n",
    "coupon_db = FAISS.load_local(\n",
    "    folder_path=FAISS_DB_PATH,\n",
    "    index_name=FAISS_INDEX_NAME,\n",
    "    embeddings=get_embedding(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "\n",
    "# 로드된 데이터를 확인\n",
    "coupon_db.index_to_docstore_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS로 similarity_search_with_relevance_scores()를 사용하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# coupon_db.similarity_search_with_relevance_scores(\"GS에서 사용할 수 있는 쿠폰을 알려주세요.\", k=4, filter=lambda d: d[\"valid_date\"] == '2024년 11월 29일')\n",
    "coupon_db.similarity_search_with_relevance_scores(\"GS에서 사용할 수 있는 쿠폰을 알려주세요.\", k=4, filter=lambda d: d[\"valid_date\"] > '2024년 11월 29일')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS에 retriever를 설정하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# retriever = coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10})\n",
    "# retriever = coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10, \"filter\": {\"valid_date\": {\"$eq\": \"2024년 11월 18일\"}}})\n",
    "retriever = coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10}, filter=lambda d: d[\"valid_date\"] < '2024년 11월 18일')\n",
    "# retriever = coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10, \"lambda_mult\": 0})\n",
    "# retriever = coupon_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "# retriever = coupon_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "retriever.invoke(\"GS에서 사용할 수 있는 쿠폰을 알려주세요.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 단어 retrieval 성능 개선을 위해 한글 형태소 분석기 라이브러리인 kiwipiepy를 설치하고 kiwi_tokenize로 BM25Retriever를 설정하여 FAISS와 앙상블로 사용"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.documents import Document\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text)]\n",
    "\n",
    "# BM25Retriever 설정\n",
    "# FAISS로부터 documents를 추출합니다.\n",
    "docs_dict = coupon_db.docstore.__dict__['_dict']\n",
    "\n",
    "# list로 저장\n",
    "docs = list(docs_dict.values())\n",
    "\n",
    "result_summary_text = []\n",
    "result_metadata = []\n",
    "\n",
    "for doc in docs:\n",
    "    result_summary_text.append(doc.page_content)\n",
    "    result_metadata.append(doc.metadata)\n",
    "\n",
    "kiwi_bm25 = BM25Retriever.from_texts(result_summary_text, metadatas=result_metadata, preprocess_func=kiwi_tokenize)\n",
    "\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[kiwi_bm25, retriever, chroma_retriever],  # 사용할 검색 모델의 리스트\n",
    "    weights=[0.3, 0.3, 0.4],  # 각 검색 모델의 결과에 적용할 가중치\n",
    "    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# retriever.invoke(\"베이글을 주문할 수 있는 쿠폰\")\n",
    "retriever.invoke(\"유효기간이 2022년 4월 28일인 쿠폰을 찾아줘\")\n",
    "# retriever.invoke(\"기프티콘 유효기간이 얼마남지 않은 쿠폰을 찾아줘\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorDB 설정 : Pinecone\n",
    "Vector DB로 Pinecone을 사용하는 경우 초기화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# env 설정 로딩\n",
    "load_dotenv()\n",
    "\n",
    "import time\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(PINECONE_INDEX_NAME).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "coupon_db = PineconeVectorStore(index=index, embedding=get_embedding())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add documents"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "coupon_db.add_texts(texts=result_summary_text, metadatas=result_metadata, ids=result_ids)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PINECONE으로 similarity_search_with_relevance_scores()를 사용하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "coupon_db.similarity_search_with_relevance_scores(\"GS에서 사용할 수 있는 쿠폰을 알려주세요.\", k=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PINECONE에 retriever를 설정하여 쿼리를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "retriever = coupon_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4, \"fetch_k\": 10})\n",
    "# retriever = coupon_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "# retriever = coupon_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "retriever.invoke(\"베이글을 주문할 수 있는 쿠폰\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "retriever.get_relevant_documents(\"베이글을 주문할 수 있는 쿠폰\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cross Encoder Reranker"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 모델 초기화\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "# 상위 3개의 문서 선택\n",
    "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "# 문서 압축 검색기 초기화\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# 압축된 문서 검색\n",
    "compressed_docs = compression_retriever.invoke(\"베이글을 주문할 수 있는 쿠폰\")\n",
    "\n",
    "# 문서 출력\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# retriever 설정\n",
    "retriever = compression_retriever"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cohere reranker"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 문서 재정렬 모델 설정\n",
    "compressor = CohereRerank(model=\"rerank-multilingual-v3.0\")\n",
    "\n",
    "# 문맥 압축 검색기 설정\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# 압축된 문서 검색\n",
    "compressed_docs = compression_retriever.invoke(\"베이글을 주문할 수 있는 쿠폰\")\n",
    "\n",
    "# 압축된 문서 출력\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# retriever 설정\n",
    "retriever = compression_retriever"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. FlashRank reranker"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# LLM 초기화\n",
    "llm = get_llm()\n",
    "\n",
    "# 문서 압축기 초기화\n",
    "compressor = FlashrankRerank(model=\"ms-marco-MultiBERT-L-12\")\n",
    "\n",
    "# 문맥 압축 검색기 초기화\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# 압축된 문서 검색\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"치즈 베이글을 주문할 수 있는 쿠폰\"\n",
    ")\n",
    "\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# 문서 ID 출력\n",
    "# print([doc.metadata[\"id\"] for doc in compressed_docs])\n",
    "\n",
    "# retriever 설정\n",
    "retriever = compression_retriever"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 검색 및 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RagResult 객체는 RAG의 답변을 저장하고 결과를 출력함"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "class RagResult:\n",
    "    def __init__(self, output):\n",
    "        \"\"\"\n",
    "        객체를 초기화합니다.\n",
    "\n",
    "        인자:\n",
    "        output: LangChain의 output 객체\n",
    "        \"\"\"\n",
    "        self.output = output\n",
    "\n",
    "    def display_description(self, description):\n",
    "        \"\"\"\n",
    "        쿠폰 설명을 표시합니다.\n",
    "\n",
    "        인자:\n",
    "        img_path (str): 이미지 경로\n",
    "        \"\"\"\n",
    "        print(f'{description}')\n",
    "\n",
    "    def display_image(self, img_path):\n",
    "        \"\"\"\n",
    "        쿠폰 이미지를 표시합니다.\n",
    "\n",
    "        인자:\n",
    "        img_path (str): 쿠폰 이미지 경로\n",
    "        \"\"\"\n",
    "        img_str = self.convert_to_base64(Image.open(img_path))\n",
    "        resize_img_str = self.resize_base64_image(img_str)\n",
    "        self.plt_img_base64(resize_img_str)\n",
    "    \n",
    "    def display(self): \n",
    "        result = self.output\n",
    "        self.display_description(result[\"answer\"])\n",
    "\n",
    "        if isinstance(result[\"image_path\"], str) and os.path.isfile(result[\"image_path\"]):\n",
    "            self.display_image(result[\"image_path\"])\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def answer(self): \n",
    "        return self.output[\"answer\"]\n",
    "    \n",
    "    def convert_to_base64(self, pil_image):\n",
    "        \"\"\"\n",
    "        PIL 이미지를 Base64로 인코딩된 문자열로 변환합니다.\n",
    "\n",
    "        :param pil_image: PIL 이미지\n",
    "        :return: 크기 조정된 Base64 문자열\n",
    "        \"\"\"\n",
    "\n",
    "        buffered = BytesIO()\n",
    "        pil_image.save(buffered, format=\"JPEG\")  # 필요한 경우 형식을 변경할 수 있습니다.\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        return img_str\n",
    "\n",
    "    def plt_img_base64(self, img_base64):\n",
    "        \"\"\"\n",
    "        Base64로 인코딩된 문자열을 이미지로 표시합니다.\n",
    "\n",
    "        :param img_base64:  Base64 문자열\n",
    "        \"\"\"\n",
    "        # Base64 문자열을 소스로 사용하여 HTML img 태그 생성\n",
    "        image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "        # HTML을 렌더링하여 이미지 표시\n",
    "        display(HTML(image_html))\n",
    "    \n",
    "    def encode_image(img_path):\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            image_content = image_file.read()\n",
    "            file_ext = os.path.splitext(img_path)[1].lower()\n",
    "            if file_ext in [\".jpg\", \".jpeg\"]:\n",
    "                mime_type = \"image/jpeg\"\n",
    "            elif file_ext == \".png\":\n",
    "                mime_type = \"image/png\"\n",
    "            else:\n",
    "                mime_type = \"image/unknown\"\n",
    "            return f\"data:{mime_type};base64,{base64.b64encode(image_content).decode('utf-8')}\"\n",
    "    \n",
    "    def resize_base64_image(self, base64_string, ratio=(0.5)):\n",
    "        \"\"\"\n",
    "        Base64 문자열로 인코딩된 이미지의 크기를 조정합니다.\n",
    "\n",
    "        인자:\n",
    "        base64_string (str): 원본 이미지의 Base64 문자열.\n",
    "        ratio (float): 이미지 비율\n",
    "\n",
    "        반환:\n",
    "        str: 크기가 조정된 이미지의 Base64 문자열.\n",
    "        \"\"\"\n",
    "        img_data = base64.b64decode(base64_string)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        width, height = img.size \n",
    "        newsize = (int(width * ratio), int(height * ratio))\n",
    "        resized_img = img.resize(newsize, Image.LANCZOS)\n",
    "        buffered = io.BytesIO()\n",
    "        resized_img.save(buffered, format=img.format)\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    def plt_img_base64(self, img_base64):\n",
    "        \"\"\"\n",
    "        Base64로 인코딩된 이미지를 표시합니다.\n",
    "\n",
    "        인자:\n",
    "        img_base64 (str): Base64로 인코딩된 이미지 문자열\n",
    "        \"\"\"\n",
    "        image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "        display(HTML(image_html))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM을 사용하여 Retrieval된 Context를 기반으로 질문에 대한 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "import json \n",
    "from operator import itemgetter\n",
    "\n",
    "class GenerationResult(BaseModel):\n",
    "    answer: str = Field(description=\"Answer\")\n",
    "    image_path: str = Field(description=\"Only image path assigned to [image_path] within the selected paragraph\")\n",
    "\n",
    "generation_result_parser = JsonOutputParser(pydantic_object=GenerationResult)\n",
    "\n",
    "# 프롬프트 생성\n",
    "generation_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that 'NO'. Use three sentences maximum and keep the answer concise.\n",
    "        답변은 한국어로 아래 FORMAT을 참고해서 json형태로만 출력해 주세요. 답변 json의 image_path 값은 선택된 문단에서 [image_path]에 할당된 값입니다. 정답을 모르면 'NO'라고 답변해 주세요.\n",
    "        Format: {format_instructions}\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "generation_prompt = generation_prompt.partial(format_instructions=generation_result_parser.get_format_instructions())\n",
    "\n",
    "# llm 로딩\n",
    "generation_llm = get_llm()\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    result = \"\\n\\n\"\n",
    "    for doc in docs:\n",
    "        result += f'[summary]:{doc.page_content}\\n[image_path]:{doc.metadata[\"image_path\"]}\\n\\n'    \n",
    "    # print('======== format_docs ========')\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def display_result(output):\n",
    "    # print('======== display_result ========')\n",
    "    # print(output)\n",
    "    coupon_result = RagResult(output)\n",
    "    result = coupon_result.display()\n",
    "    return output\n",
    "\n",
    "def answer(output):\n",
    "    # print('======== answer ========')\n",
    "    # print(output)\n",
    "    coupon_result = RagResult(output)\n",
    "    return coupon_result.answer()\n",
    "\n",
    "# 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | generation_llm\n",
    "    | JsonOutputParser()\n",
    "    | display_result\n",
    ")\n",
    "\n",
    "rag_chain_with_llama = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | get_llm('OLLAMA')\n",
    "    | JsonOutputParser()\n",
    "    | display_result\n",
    ")\n",
    " \n",
    "# 평가용 체인 생성 - llm : OpenAI\n",
    "rag_evaluation_chain_with_openai = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | generation_llm\n",
    "    | JsonOutputParser()\n",
    "    | answer\n",
    ")\n",
    "\n",
    "# 평가용 체인 생성 - llm : OLLAMA\n",
    "rag_evaluation_chain_with_llama = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | get_llm('OLLAMA')\n",
    "    | JsonOutputParser()\n",
    "    | answer\n",
    ")\n",
    "\n",
    "rag_evaluation_chain_with_langsmith_ragas = (\n",
    "    {\"context\": retriever | format_docs, \"question\": (lambda x: x[\"question\"]) | RunnablePassthrough()}\n",
    "    | generation_prompt\n",
    "    | generation_llm\n",
    "    | JsonOutputParser()\n",
    "    | answer\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 쿼리로 이미지 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 쿼리 예제\n",
    "# query = \"치킨 쿠폰을 알려줘\"\n",
    "# query = \"푸라닭 치킨 쿠폰을 알려줘\"\n",
    "# query = \"스타벅스에서 사용할 수 있는 쿠폰의 상품명은 무엇인가요?\"\n",
    "# query = \"GS에서 사용 가능 한 쿠폰을 알려줘\"\n",
    "# query = \"아메리카노를 주문할 수 있는 쿠폰을 알려줘\"\n",
    "query = \"베이글 관련 쿠폰을 알려줘\"\n",
    "# query = \"치킨을 주문할 수 있는 쿠폰 정보를 알려줘!\"\n",
    "# query = \"아이폰 주문 관련 쿠폰을 알려줘\"\n",
    "# query = \"유효기간이 2025년 03월 22일인 쿠폰을 찾아줘\"\n",
    "# query = \"유효기간이 2025년 08월 06일인 쿠폰을 찾아줘\"\n",
    "# query = \"2025년 08월 06일\"\n",
    "\n",
    "# 다음 단계 GroundChecker로 relevance 체크를 위해 output 설정\n",
    "output = rag_chain.invoke(query)\n",
    "# output = rag_chain_with_llama.invoke(query)\n",
    "\n",
    "print(output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. GroundChecker로 답변-문서 간 관련성 여부 확인\n",
    "- Upstage 의 UpstageGroundednessCheck()를 사용하여 검증\n",
    "- .env 파일에 UPSTAGE_API_KEY가 등록되어 있어야함\n",
    "- 비용 : $1 / 1M tokens\n",
    "  - https://www.upstage.ai/pricing\n",
    "- context, answer를 전달하면 결과로 grounded 또는 notGrounded 를 리턴함"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "# Upstage 문서 관련성 체크 기능을 설정합니다. https://upstage.ai\n",
    "# context, answer를 전달하면 결과로 grounded 또는 notGrounded 를 리턴함\n",
    "upstage_ground_checker = UpstageGroundednessCheck()\n",
    "\n",
    "def groundness_format_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc.page_content}</content><image_path>{doc.metadata['image_path']}</image_path></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# notGrounded 예시 : 앞서 실행과 관련 없는 context를 추출함\n",
    "# query = \"치킨 쿠폰을 알려줘\"\n",
    "# query = \"스타벅스 쿠폰을 알려줘\"\n",
    "\n",
    "# RAG 결과에 사용한 context\n",
    "context = groundness_format_docs(retriever.invoke(query))\n",
    "# print(context)\n",
    "\n",
    "# RAG 결과인 answer\n",
    "answer = output['answer']\n",
    "\n",
    "# 업스테이지 문서 관련성 체크를 실행합니다.\n",
    "ground_check_result = upstage_ground_checker.run(\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    ")\n",
    "print(ground_check_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 데이터셋 생성\n",
    "#### AutoRAG"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from autorag.data.legacy.corpus import langchain_documents_to_parquet\n",
    "\n",
    "corpus_path = f'{PROJECT_ROOT_PATH}/corpus_data/corpus.parquet'\n",
    "\n",
    "# vectorDB로부터 documents를 추출합니다.\n",
    "docs_dict = coupon_db.docstore.__dict__['_dict']\n",
    "\n",
    "# list로 저장\n",
    "docs = list(docs_dict.values())\n",
    "    \n",
    "# document를 parquet형태로 변환\n",
    "corpus_df = langchain_documents_to_parquet(docs, corpus_path, upsert=True)\n",
    "corpus_df.head(50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contents로부터 QA를 생성하여 qa.parquet 형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from autorag.data.legacy.qacreation import generate_qa_llama_index, make_single_content_qa\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# prompt = \"\"\"다음은 쿠폰 정보입니다. \n",
    "# 쿠폰 정보를 보고 할 만한 질문을 만드세요.\n",
    "# 반드시 쿠폰정보와 관련한 질문이어야 합니다.\n",
    "# 쿠폰을 사용할 수 있는 상품명과 사용처가 질문에 포함되어야 합니다.\n",
    "# 만약 주어진 쿠폰정보 내용이 쿠폰과 관련되지 않았다면, \n",
    "# '쿠폰과 관련 없습니다.'라고 질문을 만드세요.\n",
    "# 쿠폰정보:\n",
    "# {{text}}\n",
    "# 생성할 질문 개수: {{num_questions}}\n",
    "# 예시:\n",
    "# [Q]: 파리바게뜨에서 사용가능한 \"파리바게뜨 B 초코반 딸기반 케이크\" 쿠폰정보는?\n",
    "# [A]: 파리바게뜨에서 사용할 수 있는 쿠폰은 \"파리바게뜨 B 초코반 딸기반 케이크\" 쿠폰입니다. 쿠폰코드는 92001857690229이며, 유효기간은 2025년 10월 08일까지입니다.\n",
    "# [Q]: 'BBQ 황을반~BBC양념반+콜라1.25 L' 쿠폰 번호를 알려줘\n",
    "# [A]: BBQ에서 사용가능한 쿠폰은 'BBQ 황을반~BBC양념반+콜라1.25 L'이며 쿠폰의 코드 번호는 725044727165 입니다.\n",
    "# [Q]: 치킨을 주문할 수 있는 쿠폰번호는?\n",
    "# [A]: 쿠폰의 코드 번호는 725044727165 입니다.\n",
    "# [Q]: 스타벅스 아이스아메리카노를 주문할 수 있는 쿠폰번호는?\n",
    "# [A]: 쿠폰의 코드 번호는 725044727165 입니다.\n",
    "# [Q]: GS 편의점에서 사용 가능한 쿠폰의 유효기간은?\n",
    "# [A]: 유효기간은 2025년 3월 25일입니다.\n",
    "# [Q]: GS25에서 사용 가능한 쿠폰의 유효기간은?\n",
    "# [A]: 유효기간은 2025년 3월 25일입니다.\n",
    "# 쿠폰 관련이 없는 내용일 경우 예시:\n",
    "# [Q]: 쿠폰과 관련 없습니다.\n",
    "# [A]: 쿠폰과 관련 없습니다.\n",
    "# 결과:\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"다음은 쿠폰 정보입니다. \n",
    "쿠폰 정보를 보고 할 만한 질문을 만드세요.\n",
    "반드시 쿠폰정보와 관련한 질문이어야 합니다.\n",
    "쿠폰을 사용할 수 있는 상품명과 사용처가 질문에 포함되어야 합니다. 쿠폰 정보, 쿠폰 코드, 유효기간을 물어보는 질문이어야 합니다.\n",
    "만약 주어진 쿠폰정보 내용이 쿠폰과 관련되지 않았다면, \n",
    "'쿠폰과 관련 없습니다.'라고 질문을 만드세요.\n",
    "쿠폰정보:\n",
    "{{text}}\n",
    "생성할 질문 개수: {{num_questions}}\n",
    "예시:\n",
    "[Q]: 파리바게뜨에서 사용가능한 \"파리바게뜨 B 초코반 딸기반 케이크\" 쿠폰정보는 무엇인가요?\n",
    "[A]: 파리바게뜨에서 사용할 수 있는 쿠폰은 \"파리바게뜨 B 초코반 딸기반 케이크\" 쿠폰입니다. 쿠폰코드는 92001857690229이며, 유효기간은 2025년 10월 08일까지입니다.\n",
    "[Q]: 'BBQ 황을반~BBC양념반+콜라1.25 L' 쿠폰 번호는 무엇인가요?\n",
    "[A]: BBQ에서 사용가능한 쿠폰은 'BBQ 황을반~BBC양념반+콜라1.25 L'이며 쿠폰의 코드 번호는 725044727165 입니다.\n",
    "[Q]: '시그니처 생딸기 우유생크림케이크' 쿠폰의 유효기간 언제인가요?\n",
    "[A]: 유효기간은 2025년 10월 08일입니다.\n",
    "[Q]: 굽네치킨을 주문할 수 있는 쿠폰번호는 무엇인가요?\n",
    "[A]: 쿠폰의 코드 번호는 725044727165 입니다.\n",
    "[Q]: '스타벅스 카페 아메리카노 T 2잔 + 클라우드 치즈 케이크'를 주문할 수 있는 쿠폰번호는 무엇인가요?\n",
    "[A]: 쿠폰의 코드 번호는 761603284683 입니다.\n",
    "[Q]: GS 편의점에서 사용 가능한 쿠폰의 유효기간은 언제인가요?\n",
    "[A]: 유효기간은 2025년 3월 25일입니다.\n",
    "쿠폰 관련이 없는 내용일 경우 예시:\n",
    "[Q]: 쿠폰과 관련 없습니다.\n",
    "[A]: 쿠폰과 관련 없습니다.\n",
    "결과:\n",
    "\"\"\"\n",
    "save_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa.parquet'\n",
    "qa_size = 20\n",
    "corpus_df = pd.read_parquet('./corpus_data/corpus.parquet', engine='pyarrow')\n",
    "\n",
    "llm = OpenAI(model='gpt-4o-mini', temperature=0.0)\n",
    "\n",
    "qa_df = make_single_content_qa(\n",
    "    corpus_df, \n",
    "    content_size=qa_size, \n",
    "    qa_creation_func=generate_qa_llama_index,\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    question_num_per_content=1\n",
    "    )\n",
    "# delete if the output question is '쿠폰과 관련 없습니다'\n",
    "qa_df = qa_df.loc[~qa_df['query'].str.contains('쿠폰과 관련 없습니다')]\n",
    "qa_df.reset_index(drop=True, inplace=True)\n",
    "qa_df.to_parquet(save_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 qa.parquet를 qa_data로 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_parquet_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa.parquet'\n",
    "qa_data = pd.read_parquet(qa_parquet_path, engine='pyarrow')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human-in-the-loop시 편의성을 위해 parquet형태를 excel 형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "save_excel_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa.xlsx'\n",
    "qa_data.to_excel(save_excel_path, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 위해 qa데이터를 변환합니다. \n",
    "- query => question, generation_gt => ground_truth\n",
    "- ground_truth : ndarray를 str으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "qa_data = qa_data[['query', 'generation_gt']]\n",
    "qa_data.columns = ['question', 'ground_truth']\n",
    "qa_data['ground_truth'] = qa_data['ground_truth'].apply(lambda x: x[0] )\n",
    "qa_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG 실행 결과로 answer, contexts를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "# cohere API가 분당 10개 이므로 delay가 필요함\n",
    "# def invoke_with_delay(x):\n",
    "#     time.sleep(7)\n",
    "#     return rag_evaluation_chain_with_openai.invoke(x)\n",
    "\n",
    "# def get_relevant_documents_with_delay(x):\n",
    "#     time.sleep(7)\n",
    "#     return [d.page_content for d in retriever.get_relevant_documents(x)]\n",
    "\n",
    "# qa_data['answer'] = qa_data['question'].apply(lambda x: invoke_with_delay(x))\n",
    "# qa_data['contexts'] = qa_data['question'].apply(lambda x: get_relevant_documents_with_delay(x) )\n",
    "\n",
    "qa_data['answer'] = qa_data['question'].apply(lambda x: rag_evaluation_chain_with_openai.invoke(x) )\n",
    "qa_data['contexts'] = qa_data['question'].apply(lambda x: [d.page_content for d in retriever.get_relevant_documents(x)])\n",
    "\n",
    "qa_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qa_result를 parquet형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "save_qa_result_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa_result.parquet'\n",
    "qa_data.to_parquet(save_qa_result_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human-in-the-loop시 편의성을 위해 parquet형태를 excel 형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "save_qa_result_excel_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa_result.xlsx'\n",
    "\n",
    "qa_data.to_excel(save_qa_result_excel_path, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA 결과 로딩 : 저장된 qa_result.parquet를 qa_data로 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_result_parquet_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa_result.parquet'\n",
    "qa_data = pd.read_parquet(qa_result_parquet_path, engine='pyarrow')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question, ground_truth, answer, contexts를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datasets import Dataset \n",
    "dataset = Dataset.from_pandas(qa_data)\n",
    "dataset[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) RAGAS 활용"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "# 데이터셋 생성기\n",
    "langchain_llm = get_llm()\n",
    "\n",
    "# 문서 임베딩\n",
    "langchain_embeddings = get_embedding()\n",
    "\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ],\n",
    "    llm=langchain_llm, \n",
    "    embeddings=langchain_embeddings,\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "\n",
    "result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) LangSmith 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith에서 사용하는 DATASET_NAME 설정"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATASET_NAME = 'RAG_EVAL_DATASET_1130_OPENAI_FAISS_BM25_COHERE_QA'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA 결과 로딩"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_parquet_path=f'{PROJECT_ROOT_PATH}/corpus_data/qa.parquet'\n",
    "qa_data = pd.read_parquet(qa_parquet_path, engine='pyarrow')\n",
    "qa_data = qa_data[['query', 'generation_gt']]\n",
    "qa_data.columns = ['question', 'answer']\n",
    "qa_data['answer'] = qa_data['answer'].apply(lambda x: x[0] )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 위한 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": rag_evaluation_chain_with_openai.invoke(inputs[\"question\"])}\n",
    "\n",
    "# # 사용자 질문 예시\n",
    "# llm_answer = ask_question(\n",
    "#     {\"question\": \"푸라닭 치킨 쿠폰을 알려줘\"}\n",
    "# )\n",
    "# llm_answer\n",
    "\n",
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()\n",
    "\n",
    "# Context 를 반환하는 RAG 결과 반환 함수\n",
    "def context_answer_rag_answer(inputs: dict):\n",
    "    context = retriever.invoke(inputs[\"question\"])\n",
    "    return {\n",
    "        \"contexts\": \"\\n\".join([doc.page_content for doc in context]),\n",
    "        \"answer\": rag_evaluation_chain_with_openai.invoke(inputs[\"question\"]),\n",
    "        \"query\": inputs[\"question\"],\n",
    "    }\n",
    "\n",
    "# 함수 실행\n",
    "# context_answer_rag_answer(\n",
    "#     {\"question\": \"푸라닭 치킨 쿠폰을 알려줘\"}\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith dataset에 qa data 추가(20개))  \n",
    "실험 초기에 1회만 실행합니다.(반복 실행하면 데이터가 추가되어서 실험 데이터가 늘어납니다.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = create_dataset(client, DATASET_NAME)\n",
    "\n",
    "# 생성된 데이터셋에 예제 추가\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in qa_data[\"question\"].tolist()],\n",
    "    outputs=[{\"ground_truth\": a} for a in qa_data[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) QA 평가"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\"qa\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "# print_evaluator_prompt(qa_evalulator)\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator 를 활용한 평가\",\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) COT_QA / Context_QA 평가"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# cot_qa 평가자 생성\n",
    "cot_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],  # LLM 이 생성한 답변\n",
    "        \"reference\": run.outputs[\"contexts\"],  # Context\n",
    "        \"input\": example.inputs[\"question\"],  # 데이터셋의 질문\n",
    "    },\n",
    ")\n",
    "\n",
    "# context_qa 평가자 생성\n",
    "context_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"context_qa\",\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],  # LLM 이 생성한 답변\n",
    "        \"reference\": run.outputs[\"contexts\"],  # Context\n",
    "        \"input\": example.inputs[\"question\"],  # 데이터셋의 질문\n",
    "    },\n",
    ")\n",
    "\n",
    "# 프롬프트 출력\n",
    "# print_evaluator_prompt(cot_qa_evaluator)\n",
    "\n",
    "# 평가 실행\n",
    "evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=[cot_qa_evaluator, context_qa_evaluator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    metadata={\n",
    "        \"variant\": \"QA & COT_QA & Context_QA Evaluator 를 활용한 평가\",\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) labeled_criteria / relevance 평가"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# labeled_criteria 평가자 생성\n",
    "labeled_criteria_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\": get_llm(),\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": example.outputs[\"ground_truth\"],  # 정답 답변\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# evaluator prompt 출력\n",
    "# print_evaluator_prompt(labeled_criteria_evaluator)\n",
    "\n",
    "# relevance 평가자 생성\n",
    "relevance_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": \"relevance\",\n",
    "        \"llm\": get_llm(),\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": run.outputs[\"contexts\"],  # Context 를 전달\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# evaluator prompt 출력\n",
    "# print_evaluator_prompt(relevance_evaluator)\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=[labeled_criteria_evaluator, relevance_evaluator],\n",
    "    experiment_prefix=\"LABELED-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"labeled_criteria evaluator 활용한 평가\",\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Embedding 거리 기반 평가"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "from langsmith.evaluation import evaluate\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# upstage_embedding_evaluator = LangChainStringEvaluator(\n",
    "#     \"embedding_distance\",\n",
    "#     config={\n",
    "#         # OpenAIEmbeddings 가 기본 값으로 설정되어 있으나, 변경이 가능\n",
    "#         \"embeddings\": UpstageEmbeddings(model=\"solar-embedding-1-large-query\"),\n",
    "#         \"distance_metric\": \"euclidean\",  # \"cosine\", \"euclidean\", \"chebyshev\", \"hamming\", and \"manhattan\"\n",
    "#     },\n",
    "# )\n",
    "\n",
    "openai_embedding_evaluator = LangChainStringEvaluator(\n",
    "    \"embedding_distance\",\n",
    "    config={\n",
    "        # OpenAIEmbeddings 가 기본 값으로 설정되어 있으나, 변경이 가능\n",
    "        \"embeddings\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"distance_metric\": \"euclidean\",  # \"cosine\", \"euclidean\", \"chebyshev\", \"hamming\", and \"manhattan\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=[openai_embedding_evaluator],\n",
    "    experiment_prefix=\"EMBEDDING-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"embedding_distance 활용한 평가\",\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Heuristic 평가\n",
    "평가자 함수 생성 & 평가"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.evaluation import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiTokenizer\n",
    "import os\n",
    "import warnings\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "wn.ensure_loaded()\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "# 토크나이저 선언\n",
    "kiwi_tokenizer = KiwiTokenizer()\n",
    "\n",
    "def rouge_evaluator(metric: str = \"rouge1\") -> dict:\n",
    "    # wrapper function 정의\n",
    "    def _rouge_evaluator(run: Run, example: Example) -> dict:\n",
    "        # 출력값과 정답 가져오기\n",
    "        student_answer = run.outputs.get(\"answer\", \"\")\n",
    "        reference_answer = example.outputs.get(\"ground_truth\", \"\")\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True, tokenizer=KiwiTokenizer()\n",
    "        )\n",
    "        scores = scorer.score(reference_answer, student_answer)\n",
    "\n",
    "        # ROUGE 점수 반환\n",
    "        rouge = scores[metric].fmeasure\n",
    "\n",
    "        return {\"key\": \"ROUGE\", \"score\": rouge}\n",
    "\n",
    "    return _rouge_evaluator\n",
    "\n",
    "\n",
    "def bleu_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"ground_truth\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"sentence\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"sentence\")\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"BLEU\", \"score\": bleu_score}\n",
    "\n",
    "\n",
    "def meteor_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"ground_truth\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"list\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"list\")\n",
    "\n",
    "    # METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"METEOR\", \"score\": meteor}\n",
    "\n",
    "\n",
    "def semscore_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"ground_truth\", \"\")\n",
    "\n",
    "    # SentenceTransformer 모델 로드\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "    # 문장 임베딩 생성\n",
    "    student_embedding = model.encode(student_answer, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_answer, convert_to_tensor=True)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_similarity = util.pytorch_cos_sim(\n",
    "        student_embedding, reference_embedding\n",
    "    ).item()\n",
    "\n",
    "    return {\"key\": \"sem_score\", \"score\": cosine_similarity}\n",
    "\n",
    "\n",
    "# 평가자 정의\n",
    "heuristic_evalulators = [\n",
    "    rouge_evaluator(metric=\"rougeL\"),\n",
    "    bleu_evaluator,\n",
    "    meteor_evaluator,\n",
    "    semscore_evaluator,\n",
    "]\n",
    "\n",
    "# 실험 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=heuristic_evalulators,\n",
    "    experiment_prefix=\"Heuristic-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Heuristic-EVAL (Rouge, BLEU, METEOR, SemScore) 을 사용하여 평가\",\n",
    "    },\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Groundedness 평가(Upstage Upstage Groundness Checker API 사용)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.evaluation import evaluate\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "# Upstage 문서 관련성 체크 기능을 설정합니다. https://upstage.ai\n",
    "# context, answer를 전달하면 결과로 grounded 또는 notGrounded 를 리턴함\n",
    "upstage_groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "def upstage_groundness_check_evaluator(run: Run, example: Example) -> dict:\n",
    "    # LLM 생성 답변, 정답 답변 가져오기\n",
    "    answer = run.outputs.get(\"answer\", \"\")\n",
    "    context = run.outputs.get(\"contexts\", \"\")\n",
    "\n",
    "    # Groundness 체크\n",
    "    groundedness_score = upstage_groundedness_check.invoke(\n",
    "        {\"answer\": answer, \"context\": context}\n",
    "    )\n",
    "    groundedness_score = groundedness_score == \"grounded\"\n",
    "\n",
    "    return {\"key\": \"groundness_score\", \"score\": int(groundedness_score)}\n",
    "\n",
    "# 실행\n",
    "experiment_results = evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=DATASET_NAME,\n",
    "    evaluators=[upstage_groundness_check_evaluator],\n",
    "    experiment_prefix=\"GROUNDEDNESS-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Upstage Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
